// src/hooks/useCameraKit.ts - Stream Rotator + Push2Web integration
import { useState, useRef, useCallback, useEffect } from 'react';
import { bootstrapCameraKit, createMediaStreamSource, Transform2D } from '@snap/camera-kit';
import { Push2Web } from '@snap/push2web';
import { validateConfig } from '../config/cameraKit';
import type { CameraState } from './useCameraPermissions';

let cameraKitInstance: any = null;
let preloadPromise: Promise<any> | null = null;
let push2WebInstance: Push2Web | null = null;

const withTimeout = <T>(promise: Promise<T>, ms: number): Promise<T> => {
  return Promise.race([
    promise,
    new Promise<T>((_, reject) => 
      setTimeout(() => reject(new Error(`Timeout after ${ms}ms`)), ms)
    )
  ]);
};

/**
 * STREAM ROTATOR: Rotate landscape 2560x1440 ‚Üí portrait 1440x2560
 * This fixes Firefox upside-down issue by pre-rotating stream before Camera Kit
 */
const rotateStreamToPortrait = (landscapeStream: MediaStream, addLog: (msg: string) => void): MediaStream => {
  try {
    const videoTrack = landscapeStream.getVideoTracks()[0];
    const audioTracks = landscapeStream.getAudioTracks();
    
    if (!videoTrack) {
      addLog('‚ùå No video track to rotate');
      return landscapeStream;
    }

    const settings = videoTrack.getSettings();
    const originalWidth = settings.width || 2560;
    const originalHeight = settings.height || 1440;
    const isLandscape = originalWidth > originalHeight;
    
    addLog(`üîÑ Stream Rotator: ${originalWidth}√ó${originalHeight} (${isLandscape ? 'landscape' : 'portrait'})`);
    
    if (!isLandscape) {
      addLog('‚ÑπÔ∏è Stream already portrait - no rotation needed');
      return landscapeStream;
    }

    // Create canvas for rotation
    const canvas = document.createElement('canvas');
    const ctx = canvas.getContext('2d');
    
    if (!ctx) {
      addLog('‚ùå Cannot create canvas context for rotation');
      return landscapeStream;
    }

    // Set rotated dimensions: landscape width‚Üíportrait height, landscape height‚Üíportrait width
    const rotatedWidth = originalHeight;   // 1440 (from landscape height)
    const rotatedHeight = originalWidth;   // 2560 (from landscape width)
    
    canvas.width = rotatedWidth;
    canvas.height = rotatedHeight;
    
    addLog(`üéØ Rotation target: ${rotatedWidth}√ó${rotatedHeight} portrait`);

    // Create video element
    const video = document.createElement('video');
    video.srcObject = landscapeStream;
    video.autoplay = true;
    video.muted = true;
    video.playsInline = true;

    // Firefox MediaStream detection
    const isFirefox = navigator.userAgent.toLowerCase().includes('firefox');
    const isMediaStream = landscapeStream instanceof MediaStream;

    // Rotation rendering function with Firefox fix
    const renderRotatedFrame = () => {
      if (video.readyState >= 2) { // HAVE_CURRENT_DATA
        ctx.save();
        
        if (isFirefox && isMediaStream) {
          // Firefox MediaStream fix - flip Y-axis before rotation
          ctx.translate(rotatedWidth / 2, rotatedHeight / 2);
          ctx.scale(1, -1); // Flip Y-axis for Firefox MediaStream bug
          ctx.rotate(Math.PI / 2); // 90¬∞ clockwise
          ctx.translate(-originalWidth / 2, -originalHeight / 2);
          addLog('ü¶ä Firefox MediaStream rotation with Y-flip applied');
        } else {
          // Normal rotation for other browsers
          ctx.translate(rotatedWidth / 2, rotatedHeight / 2);
          ctx.rotate(Math.PI / 2); // 90¬∞ clockwise
          ctx.translate(-originalWidth / 2, -originalHeight / 2);
        }
        
        // Draw rotated video frame
        ctx.drawImage(video, 0, 0, originalWidth, originalHeight);
        ctx.restore();
      }
      
      requestAnimationFrame(renderRotatedFrame);
    };

    // Start rotation loop when video loads
    video.addEventListener('loadeddata', () => {
      addLog(`‚úÖ Video loaded: ${video.videoWidth}√ó${video.videoHeight}`);
      renderRotatedFrame();
    });

    // Create rotated stream from canvas
    const rotatedCanvasStream = canvas.captureStream(30); // 30fps
    
    // Preserve audio tracks
    audioTracks.forEach(audioTrack => {
      const clonedAudioTrack = audioTrack.clone();
      rotatedCanvasStream.addTrack(clonedAudioTrack);
      addLog(`üé§ Audio track preserved: ${audioTrack.label}`);
    });

    addLog(`üîÑ Stream rotated: ${originalWidth}√ó${originalHeight} ‚Üí ${rotatedWidth}√ó${rotatedHeight}`);
    return rotatedCanvasStream;

  } catch (error) {
    addLog(`‚ùå Stream rotation failed: ${error}`);
    return landscapeStream; // Fallback to original
  }
};

const preloadCameraKit = async () => {
  if (cameraKitInstance) return { cameraKit: cameraKitInstance, push2Web: push2WebInstance };
  if (preloadPromise) return preloadPromise;
  
  preloadPromise = (async () => {
    try {
      if (location.protocol !== 'https:' && location.hostname !== 'localhost') {
        throw new Error('HTTPS_REQUIRED');
      }
      
      validateConfig();
      
      // Initialize Push2Web
      push2WebInstance = new Push2Web();
      
      // Bootstrap Camera Kit with Push2Web extension
      cameraKitInstance = await bootstrapCameraKit(
        { 
          apiToken: import.meta.env.VITE_CAMERA_KIT_API_TOKEN || 'eyJhbGciOiJIUzI1NiIsImtpZCI6IkNhbnZhc1MyU0hNQUNQcm9kIiwidHlwIjoiSldUIn0.eyJhdWQiOiJjYW52YXMtY2FudmFzYXBpIiwiaXNzIjoiY2FudmFzLXMyc3Rva2VuIiwibmJmIjoxNzQ3MDM1OTAyLCJzdWIiOiI2YzMzMWRmYy0zNzEzLTQwYjYtYTNmNi0zOTc2OTU3ZTkyZGZ-UFJPRFVDVElPTn5jZjM3ZDAwNy1iY2IyLTQ3YjEtODM2My1jYWIzYzliOGJhM2YifQ.UqGhWZNuWXplirojsPSgZcsO3yu98WkTM1MRG66dsHI'
        },
        (container) => {
          container.provides(push2WebInstance!.extension);
          return container;
        }
      );
      
      return { cameraKit: cameraKitInstance, push2Web: push2WebInstance };
    } catch (error) {
      cameraKitInstance = null;
      push2WebInstance = null;
      preloadPromise = null;
      throw error;
    }
  })();
  
  return preloadPromise;
};

preloadCameraKit().catch(console.error);

export const useCameraKit = (addLog: (message: string) => void) => {
  const [cameraState, setCameraState] = useState<CameraState>('initializing');
  const [currentFacingMode, setCurrentFacingMode] = useState<'user' | 'environment'>('user');
  
  const sessionRef = useRef<any>(null);
  const streamRef = useRef<MediaStream | null>(null);
  const outputCanvasRef = useRef<HTMLCanvasElement | null>(null);
  const lensRepositoryRef = useRef<any>(null);
  const isAttachedRef = useRef<boolean>(false);
  const containerRef = useRef<React.RefObject<HTMLDivElement> | null>(null);
  const isInitializedRef = useRef<boolean>(false);
  const currentConfigRef = useRef<any>(null);
  const push2WebSubscribed = useRef<boolean>(false);

  // Push2Web event handlers
  const setupPush2WebEvents = useCallback((push2Web: Push2Web) => {
    // Lens received event
    push2Web.events.addEventListener('lensReceived', (event: any) => {
      const { id, name, iconUrl, cameraFacingPreference } = event.detail;
      addLog(`üì¶ Push2Web lens received: ${name} (${id})`);
      addLog(`   Camera preference: ${cameraFacingPreference}`);
      
      // Apply lens to current session
      if (sessionRef.current && lensRepositoryRef.current) {
        try {
          // Find lens in repository or use received lens directly
          let targetLens = lensRepositoryRef.current.find((lens: any) => lens.id === id);
          
          if (!targetLens && event.detail) {
            // Create lens object from Push2Web data
            targetLens = {
              id,
              name,
              iconUrl,
              cameraFacingPreference
            };
          }
          
          if (targetLens) {
            sessionRef.current.applyLens(targetLens).then(() => {
              addLog(`‚úÖ Push2Web lens applied: ${name}`);
            }).catch((error: any) => {
              addLog(`‚ùå Failed to apply Push2Web lens: ${error}`);
            });
          } else {
            addLog(`‚ùå Lens not found in repository: ${id}`);
          }
        } catch (error) {
          addLog(`‚ùå Push2Web lens application error: ${error}`);
        }
      } else {
        addLog(`‚ö†Ô∏è Session or repository not ready for Push2Web lens`);
      }
    });

    // Error event
    push2Web.events.addEventListener('error', (event: any) => {
      const errorDetails = event.detail;
      addLog(`‚ùå Push2Web error: ${errorDetails}`);
    });

    // Subscription changed event
    push2Web.events.addEventListener('subscriptionChanged', (event: any) => {
      const subState = event.detail;
      addLog(`üîó Push2Web subscription changed: ${subState}`);
      push2WebSubscribed.current = subState === 'subscribed';
    });

    addLog('üé≠ Push2Web event handlers configured');
  }, [addLog]);

  // Subscribe to Push2Web
  const subscribePush2Web = useCallback(async (accessToken: string): Promise<boolean> => {
    try {
      if (!push2WebInstance) {
        addLog('‚ùå Push2Web instance not available');
        return false;
      }

      if (!sessionRef.current) {
        addLog('‚ùå Camera Kit session not ready for Push2Web');
        return false;
      }

      if (!lensRepositoryRef.current) {
        addLog('‚ùå Lens repository not loaded for Push2Web');
        return false;
      }

      addLog('üîó Subscribing to Push2Web...');
      
      // Create lens repository object compatible with Push2Web
      const lensRepository = lensRepositoryRef.current;

      await push2WebInstance.subscribe(
        accessToken,
        sessionRef.current,
        lensRepository
      );

      push2WebSubscribed.current = true;
      addLog('‚úÖ Push2Web subscription successful');
      addLog('üì± Ready to receive lenses from Lens Studio');
      
      return true;
    } catch (error) {
      addLog(`‚ùå Push2Web subscription failed: ${error}`);
      push2WebSubscribed.current = false;
      return false;
    }
  }, [addLog]);

  // Get Push2Web status
  const getPush2WebStatus = useCallback(() => {
    return {
      available: !!push2WebInstance,
      subscribed: push2WebSubscribed.current,
      session: !!sessionRef.current,
      repository: !!lensRepositoryRef.current
    };
  }, []);

  const attachCameraOutput = useCallback((
    canvas: HTMLCanvasElement, 
    containerReference: React.RefObject<HTMLDivElement>
  ) => {
    if (!containerReference.current) {
      addLog('‚ùå Container not available');
      return;
    }

    try {
      requestAnimationFrame(() => {
        if (!containerReference.current) return;

        // Clear container
        while (containerReference.current.firstChild) {
          try {
            containerReference.current.removeChild(containerReference.current.firstChild);
          } catch (e) {
            break;
          }
        }
        
        outputCanvasRef.current = canvas;
        addLog(`üìä Canvas: ${canvas.width}x${canvas.height}`);
        
        // Perfect fit calculations
        const containerRect = containerReference.current.getBoundingClientRect();
        const canvasAspect = canvas.width / canvas.height;
        const containerAspect = containerRect.width / containerRect.height;
        
        let displayWidth, displayHeight;
        if (canvasAspect > containerAspect) {
          displayWidth = containerRect.width;
          displayHeight = containerRect.width / canvasAspect;
        } else {
          displayHeight = containerRect.height;
          displayWidth = containerRect.height * canvasAspect;
        }
        
        // Normal CSS - no Firefox rotation fix needed anymore
        canvas.style.cssText = `
          position: absolute;
          top: 50%;
          left: 50%;
          width: ${displayWidth}px;
          height: ${displayHeight}px;
          transform: translate(-50%, -50%);
          object-fit: contain;
          object-position: center;
          background: transparent;
          image-rendering: crisp-edges;
          will-change: transform;
          backface-visibility: hidden;
        `;
        
        containerReference.current.style.cssText = `
          position: relative;
          width: 100%;
          height: 100%;
          overflow: hidden;
          display: flex;
          align-items: center;
          justify-content: center;
          background: #000;
          touch-action: manipulation;
        `;
        
        try {
          containerReference.current.appendChild(canvas);
          isAttachedRef.current = true;
          
          const scaleX = displayWidth / canvas.width;
          const scaleY = displayHeight / canvas.height;
          addLog(`‚úÖ Canvas attached - Scale: ${scaleX.toFixed(3)}x${scaleY.toFixed(3)}`);
        } catch (e) {
          addLog(`‚ùå Attachment failed: ${e}`);
        }
      });
    } catch (error) {
      addLog(`‚ùå Canvas error: ${error}`);
    }
  }, [addLog]);

  const restoreCameraFeed = useCallback(() => {
    if (sessionRef.current && outputCanvasRef.current && containerRef.current?.current) {
      addLog('üîÑ Restoring camera feed...');
      
      const isCanvasAttached = containerRef.current.current.contains(outputCanvasRef.current);
      
      if (!isCanvasAttached) {
        addLog('üì± Re-attaching canvas');
        attachCameraOutput(outputCanvasRef.current, containerRef.current);
      }
      
      if (sessionRef.current.output?.live) {
        try {
          sessionRef.current.play('live');
          addLog('‚ñ∂Ô∏è Session resumed');
        } catch (error) {
          addLog(`‚ö†Ô∏è Resume error: ${error}`);
        }
      }
    }
  }, [addLog, attachCameraOutput]);

  const reloadLens = useCallback(async (): Promise<boolean> => {
    if (!sessionRef.current || !isInitializedRef.current) {
      addLog('‚ùå Cannot reload - session not ready');
      return false;
    }

    try {
      addLog('üîÑ Restarting AR lens...');
      
      sessionRef.current.pause();
      await new Promise(resolve => setTimeout(resolve, 200));
      
      try {
        await withTimeout(sessionRef.current.removeLens(), 2000);
        addLog('üóëÔ∏è Lens removed');
      } catch (removeError) {
        addLog(`‚ö†Ô∏è Lens removal failed: ${removeError}`);
      }
      
      await new Promise(resolve => setTimeout(resolve, 300));
      
      const lenses = lensRepositoryRef.current;
      if (lenses && lenses.length > 0 && currentConfigRef.current) {
        const targetLens = lenses.find((lens: any) => lens.id === currentConfigRef.current.lensId) || lenses[0];
        await withTimeout(sessionRef.current.applyLens(targetLens), 3000);
        addLog(`‚úÖ Lens restarted: ${targetLens.name}`);
      }
      
      sessionRef.current.play('live');
      
      setTimeout(() => {
        restoreCameraFeed();
      }, 300);
      
      addLog('üéâ AR lens restarted');
      return true;
      
    } catch (error) {
      addLog(`‚ùå Lens restart failed: ${error}`);
      
      try {
        sessionRef.current.play('live');
      } catch (recoveryError) {
        addLog(`‚ùå Recovery failed: ${recoveryError}`);
      }
      
      return false;
    }
  }, [addLog, restoreCameraFeed]);

  useEffect(() => {
    const handleVisibilityChange = () => {
      if (document.visibilityState === 'visible') {
        addLog('üëÅÔ∏è App visible - checking camera...');
        setTimeout(() => {
          restoreCameraFeed();
        }, 100);
      }
    };

    document.addEventListener('visibilitychange', handleVisibilityChange);
    
    return () => {
      document.removeEventListener('visibilitychange', handleVisibilityChange);
    };
  }, [addLog, restoreCameraFeed]);

  const initializeCameraKit = useCallback(async (
    stream: MediaStream,
    containerReference: React.RefObject<HTMLDivElement>
  ): Promise<boolean> => {
    try {
      const adaptiveConfig = {
        apiToken: import.meta.env.VITE_CAMERA_KIT_API_TOKEN,
        lensId: import.meta.env.VITE_CAMERA_KIT_LENS_ID || '04441cd2-8e9d-420b-b293-90b5df8f577f',
        lensGroupId: import.meta.env.VITE_CAMERA_KIT_LENS_GROUP_ID || 'cd5b1b49-4483-45ea-9772-cb241939e2ce',
        canvas: {
          width: Math.round(window.innerWidth * (window.devicePixelRatio || 1)),
          height: Math.round(window.innerHeight * (window.devicePixelRatio || 1))
        }
      };
      currentConfigRef.current = adaptiveConfig;
      
      if (isInitializedRef.current && sessionRef.current && cameraState === 'ready') {
        addLog('üì± Updating existing session...');
        
        // STREAM ROTATOR: Rotate landscape stream to portrait before Camera Kit
        const rotatedStream = rotateStreamToPortrait(stream, addLog);
        
        const source = createMediaStreamSource(rotatedStream, {
          transform: currentFacingMode === 'user' ? Transform2D.MirrorX : undefined,
          cameraType: currentFacingMode
        });
        
        await withTimeout(sessionRef.current.setSource(source), 3000);
        await source.setRenderSize(adaptiveConfig.canvas.width, adaptiveConfig.canvas.height);
        addLog(`‚úÖ Adaptive render: ${adaptiveConfig.canvas.width}x${adaptiveConfig.canvas.height}`);
        
        streamRef.current = rotatedStream;
        containerRef.current = containerReference;
        
        if (sessionRef.current.output?.live && containerReference.current && !isAttachedRef.current) {
          setTimeout(() => {
            if (sessionRef.current.output.live) {
              attachCameraOutput(sessionRef.current.output.live, containerReference);
            }
          }, 100);
        }
        
        addLog('‚úÖ Stream updated with rotation');
        return true;
      }

      addLog('üé≠ Initializing Camera Kit with Push2Web...');
      addLog(`üìê Adaptive canvas: ${adaptiveConfig.canvas.width}x${adaptiveConfig.canvas.height}`);
      setCameraState('initializing');
      containerRef.current = containerReference;

      const { cameraKit, push2Web } = await withTimeout(preloadCameraKit(), 10000);
      
      if (!cameraKit) {
        throw new Error('Failed to initialize Camera Kit');
      }

      // Setup Push2Web events
      if (push2Web) {
        setupPush2WebEvents(push2Web);
        addLog('‚úÖ Push2Web extension loaded');
      }

      addLog('üé¨ Creating session...');
      const session: any = await withTimeout(cameraKit.createSession(), 5000);
      sessionRef.current = session;
      isInitializedRef.current = true;
      
      session.events.addEventListener("error", (event: any) => {
        addLog(`‚ùå Session error: ${event.detail}`);
        setCameraState('error');
      });

      // STREAM ROTATOR: Rotate landscape stream to portrait before Camera Kit
      const rotatedStream = rotateStreamToPortrait(stream, addLog);
      streamRef.current = rotatedStream;

      const source = createMediaStreamSource(rotatedStream, {
        transform: currentFacingMode === 'user' ? Transform2D.MirrorX : undefined,
        cameraType: currentFacingMode
      });
      
      await withTimeout(session.setSource(source), 3000);
      addLog('‚úÖ Camera source configured with stream rotation');

      await source.setRenderSize(adaptiveConfig.canvas.width, adaptiveConfig.canvas.height);
      addLog(`‚úÖ Adaptive AR render: ${adaptiveConfig.canvas.width}x${adaptiveConfig.canvas.height}`);

      if (!lensRepositoryRef.current) {
        try {
          const lensResult: any = await withTimeout(
            cameraKit.lensRepository.loadLensGroups([adaptiveConfig.lensGroupId]), 
            5000
          );
          lensRepositoryRef.current = lensResult.lenses;
          addLog('‚úÖ Lens repository loaded');
        } catch (lensError) {
          addLog(`‚ö†Ô∏è Lens loading failed: ${lensError}`);
        }
      }

      const lenses = lensRepositoryRef.current;
      if (lenses && lenses.length > 0) {
        try {
          const targetLens = lenses.find((lens: any) => lens.id === adaptiveConfig.lensId) || lenses[0];
          await withTimeout(session.applyLens(targetLens), 3000);
          addLog(`‚úÖ Lens applied: ${targetLens.name}`);
        } catch (lensApplyError) {
          addLog(`‚ö†Ô∏è Lens application failed: ${lensApplyError}`);
        }
      }

      session.play('live');

      setTimeout(() => {
        if (session.output.live && containerReference.current && !isAttachedRef.current) {
          addLog('üé• Attaching adaptive output...');
          attachCameraOutput(session.output.live, containerReference);
        }
      }, 500);

      setCameraState('ready');
      addLog('üéâ Camera Kit + Push2Web ready with stream rotation');
      return true;

    } catch (error: any) {
      const errorMessage = error instanceof Error ? error.message : String(error);
      addLog(`‚ùå Camera Kit error: ${errorMessage}`);
      setCameraState('error');
      return false;
    }
  }, [currentFacingMode, addLog, attachCameraOutput, cameraState, setupPush2WebEvents]);

  const switchCamera = useCallback(async (): Promise<MediaStream | null> => {
    if (!sessionRef.current || !isInitializedRef.current) {
      addLog('‚ùå Cannot switch - session not initialized');
      return null;
    }

    try {
      const newFacingMode = currentFacingMode === 'user' ? 'environment' : 'user';
      addLog(`üîÑ Switching to ${newFacingMode} camera...`);

      if (sessionRef.current.output?.live) {
        sessionRef.current.pause();
        addLog('‚è∏Ô∏è Session paused');
      }

      if (streamRef.current) {
        streamRef.current.getTracks().forEach(track => {
          track.stop();
          addLog(`üõë Stopped ${track.kind} track`);
        });
        streamRef.current = null;
      }

      await new Promise(resolve => setTimeout(resolve, 200));

      // LANDSCAPE constraints for camera switch (match Brio hardware)
      const newStream = await withTimeout(
        navigator.mediaDevices.getUserMedia({
          video: { 
            facingMode: newFacingMode,
            // Request LANDSCAPE to match hardware sensor
            width: { ideal: 2560, min: 1280, max: 3840 },
            height: { ideal: 1440, min: 720, max: 2160 },
            frameRate: { ideal: 30, min: 15, max: 60 }
          },
          audio: {
            echoCancellation: true,
            noiseSuppression: true,
            autoGainControl: true,
            sampleRate: { ideal: 48000 },
            channelCount: { ideal: 2 }
          }
        }),
        5000
      );

      addLog(`‚úÖ New ${newFacingMode} LANDSCAPE stream obtained`);

      // Log new stream details with orientation check
      const videoTracks = newStream.getVideoTracks();
      const audioTracks = newStream.getAudioTracks();
      
      if (videoTracks.length > 0) {
        const settings = videoTracks[0].getSettings();
        const resolution = `${settings.width}x${settings.height}`;
        const isLandscape = (settings.width || 0) > (settings.height || 0);
        
        addLog(`üìπ New stream: ${resolution}@${settings.frameRate}fps`);
        addLog(`üîÑ Orientation: ${isLandscape ? 'LANDSCAPE ‚úÖ' : 'PORTRAIT ‚ö†Ô∏è'}`);
        
        if (!isLandscape) {
          addLog(`‚ö†Ô∏è Expected landscape, got portrait - browser may have auto-rotated`);
        }
      }
      
      addLog(`üé§ Audio tracks: ${audioTracks.length}`);

      // STREAM ROTATOR: Rotate new landscape stream to portrait before Camera Kit
      const rotatedStream = rotateStreamToPortrait(newStream, addLog);
      streamRef.current = rotatedStream;

      const source = createMediaStreamSource(rotatedStream, {
        transform: newFacingMode === 'user' ? Transform2D.MirrorX : undefined,
        cameraType: newFacingMode
      });
      
      await withTimeout(sessionRef.current.setSource(source), 3000);
      addLog('‚úÖ Source set with stream rotation');

      const config = currentConfigRef.current;
      if (config) {
        await source.setRenderSize(config.canvas.width, config.canvas.height);
        addLog(`‚úÖ Adaptive render: ${config.canvas.width}x${config.canvas.height}`);
      }

      await new Promise(resolve => setTimeout(resolve, 300));

      if (sessionRef.current.output?.live) {
        sessionRef.current.play('live');
        addLog('‚ñ∂Ô∏è Session resumed');
      }

      setCurrentFacingMode(newFacingMode);
      addLog(`üéâ Camera switched to ${newFacingMode} with rotation`);
      return rotatedStream;
      
    } catch (error: any) {
      addLog(`‚ùå Camera switch failed: ${error.message}`);
      
      try {
        if (sessionRef.current.output?.live) {
          sessionRef.current.play('live');
        }
        addLog('üîÑ Restored previous state');
      } catch (recoveryError) {
        addLog(`‚ùå Recovery failed: ${recoveryError}`);
        setCameraState('error');
      }
      
      return null;
    }
  }, [currentFacingMode, addLog]);

  const pauseSession = useCallback(() => {
    if (sessionRef.current) {
      sessionRef.current.pause();
      addLog('‚è∏Ô∏è Session paused');
    }
  }, [addLog]);

  const resumeSession = useCallback(() => {
    if (sessionRef.current) {
      sessionRef.current.play('live');
      addLog('‚ñ∂Ô∏è Session resumed');
    }
  }, [addLog]);

  const cleanup = useCallback(() => {
    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => track.stop());
      addLog('üîÑ Stream stopped');
    }
    if (sessionRef.current) {
      sessionRef.current.pause();
      addLog('‚è∏Ô∏è Session paused');
    }
    push2WebSubscribed.current = false;
    isAttachedRef.current = false;
    containerRef.current = null;
    currentConfigRef.current = null;
  }, [addLog]);

  const getCanvas = useCallback(() => {
    return outputCanvasRef.current;
  }, []);

  const getStream = useCallback(() => {
    return streamRef.current;
  }, []);

  return {
    cameraState,
    currentFacingMode,
    initializeCameraKit,
    switchCamera,
    reloadLens,
    pauseSession,
    resumeSession,
    cleanup,
    getCanvas,
    getStream,
    restoreCameraFeed,
    isReady: cameraState === 'ready',
    isInitializing: cameraState === 'initializing',
    subscribePush2Web,
    getPush2WebStatus
  };
};